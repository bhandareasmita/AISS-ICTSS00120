# ICTAII502

## Application
This unit describes the skills and knowledge required to train and evaluate the operations of machine learning (ML) models when processing previously unseen data.

The unit applies to individuals who may work across a wide range of information and communications technology (ICT) roles, including support technicians, system administrators, programmers and cloud computing engineers.

No licensing, legislative or certification requirements apply to this unit at the time of publication.

## Performance Evidence
The candidate must demonstrate the ability to complete the tasks outlined in the elements, performance criteria and foundation skills of this unit, including evidence of the ability to:
- train at least one machine learning (ML) model, where the work must include one of the following:
  - training using unsupervised ML techniques
  - training using supervised ML techniques

- evaluate the operations of at least one the above trained ML models, where the evaluation must include one of the following:
  - unsupervised ML techniques
  - supervised ML techniques.

In the course of the above, the candidate must:
- produce documentation of all performed work tasks in required organisational formats
- apply required organisational policies and procedures.

## Knowledge Evidence
The candidate must be able to demonstrate knowledge to complete the tasks outlined in the elements, performance criteria and foundation skills of this unit, including knowledge of:
- key features and functions of supervised and unsupervised ML techniques
- key features and functions of ML, including:
  - data sources
  - training, validation and test data
  - attribute names
  - target data
  - default and non-default parameters
  - feature engineering
  - learning algorithms
  - model sizes
  - metrics
- procedures for training, testing and validating data parameters
- key methods to determine ML deployment requirements for end users, including:
  - cross-industry standard process for data mining (CRISP-DM) methodology
  - software development methodology
- method to determine predictive accuracy of ML models using target data
- method to compare predictions returned by ML models against known target values
- key features and functions of industry-recognised ML models that may be trained and evaluated
- organisational formats used for documenting ML model evaluations
- organisational policies and procedures, and legislative requirements relating to work tasks.

## Elements and Performance Criteria

### 1. Evaluate data requirements

1.1 Confirm work brief and tasks according to organisational policies and procedures
1.2 Analyse ML requirements according to cross-industry standard process for data mining (CRISP-DM) methodology, where required
1.3 Confirm input machine training data source according to work brief
1.4 Confirm that data attribute names contain target according to work brief
1.5 Review data transformation instructions according to work brief
1.6 Confirm that default and non-default training parameters control required learning algorithm according to work brief

### 2. Arrange machine training datasets

2.1 Set machine training data parameters according to work brief
2.2 Select model size according to work brief
2.3 Use selected parameter and feature engineering on required training data
2.4 Finalise machine training data procedures according to work brief

### 3. Arrange validation datasets

3.1 Set validation data parameters according to work brief
3.2 Select model size according to work brief
3.3 Use selected parameter and feature engineering on required validation data
3.4 Identify any functionality issues of parameters
3.5 Refine ML parameters according to work brief

### 4. Arrange test datasets

4.1 Set test data parameters according to work brief
4.2 Select model size according to work brief
4.3 Use selected parameter and feature engineering on required test data
4.4 Identify and rectify any functionality issues in test dataset
4.5 Finalise test data procedures according to work brief

### 5. Finalise ML evaluations

5.1 Review target data outputs according to work brief
5.2 Adjust model based on any discrepancies of outputs, where required
5.3 Record predictive accuracy of ML model according to work brief
5.4 Run variables through ML model and record outputs
5.5 Compare outputs returned by ML model against target data outputs
5.6 Document metrics and accuracy of ML data predictions according to organisational policies and procedures